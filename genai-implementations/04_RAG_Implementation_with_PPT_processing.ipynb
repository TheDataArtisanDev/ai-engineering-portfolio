{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3055e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-pptx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9675144c",
   "metadata": {},
   "source": [
    "# Task 1: Loading and Processing Data from a Powerpoint Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b863eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resources...\n",
      "‚úÖ NLTK resources downloaded successfully\n",
      "\n",
      "============================================================\n",
      "LOADING POWERPOINT PRESENTATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\yaseen_banu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\yaseen_banu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Presentation loaded with 1 sections.\n",
      "\n",
      "============================================================\n",
      "VERIFYING LOADED CONTENT\n",
      "============================================================\n",
      "üìÑ First section of the PowerPoint:\n",
      "page_content='BITTE\n",
      "\n",
      "AI-Powered Customer Service Revolution\n",
      "\n",
      "Series A Funding Pitch\n",
      "\n",
      "2024\n",
      "\n",
      "\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Our Mission\n",
      "\n",
      "To revolutionize the way people interact with technology through innovative solutions.\n",
      "\n",
      "Our Product\n",
      "\n",
      "An AI-powered platform that helps businesses automate customer service while maintaining human touch.\n",
      "\n",
      "Unique Selling Point\n",
      "\n",
      "99.9% accuracy in understanding customer intent\n",
      "\n",
      "Seamless integration with existing systems\n",
      "\n",
      "Reduces customer service costs by 60%\n",
      "\n",
      "\n",
      "\n",
      "Meet Our Founders\n",
      "\n",
      "Sarah Johnson - CEO\n",
      "\n",
      "Former Google Product Manager with 10 years experience\n",
      "\n",
      "Led product development for Google Assistant\n",
      "\n",
      "Michael Chen - CTO\n",
      "\n",
      "Ex-Microsoft Engineer, AI specialist\n",
      "\n",
      "Published 15+ papers on machine learning\n",
      "\n",
      "Emma Rodriguez - CMO\n",
      "\n",
      "Marketing expert from Apple\n",
      "\n",
      "Grew Apple's B2B segment by 300%\n",
      "\n",
      "\n",
      "\n",
      "Market Analysis\n",
      "\n",
      "Target Market\n",
      "\n",
      "Mid to large enterprises with customer service teams\n",
      "\n",
      "E-commerce companies\n",
      "\n",
      "SaaS businesses\n",
      "\n",
      "Healthcare organizations\n",
      "\n",
      "Market Size\n",
      "\n",
      "$50B global customer service software market\n",
      "\n",
      "Competition\n",
      "\n",
      "Zendesk: Traditional ticketing system\n",
      "\n",
      "Intercom: Chat-focused solution\n",
      "\n",
      "Salesforce Service Cloud: Enterprise-focused\n",
      "\n",
      "\n",
      "\n",
      "Financial Projections & Funding\n",
      "\n",
      "Revenue Projections\n",
      "\n",
      "Year 1: $2M revenue, 50 enterprise clients\n",
      "\n",
      "Year 2: $8M revenue, 200 clients\n",
      "\n",
      "Year 3: $25M revenue, 500+ clients\n",
      "\n",
      "Funding Ask: $5M Series A\n",
      "\n",
      "Use of Funds\n",
      "\n",
      "40% Product development\n",
      "\n",
      "30% Sales & Marketing\n",
      "\n",
      "20% Team expansion\n",
      "\n",
      "10% Operations\n",
      "\n",
      "Current Team: 25 employees across engineering, sales, and support\n",
      "\n",
      "\n",
      "\n",
      "Technology & Innovation\n",
      "\n",
      "AI Technology Stack\n",
      "\n",
      "Natural Language Processing (NLP)\n",
      "\n",
      "Machine Learning algorithms for intent recognition\n",
      "\n",
      "Deep learning models for conversation flow\n",
      "\n",
      "Key Features\n",
      "\n",
      "Multi-language support (20+ languages)\n",
      "\n",
      "Real-time sentiment analysis\n",
      "\n",
      "Automated escalation to human agents\n",
      "\n",
      "Integration with popular CRM systems' metadata={'source': 'Bitte pitch deck.pptx'}\n",
      "\n",
      "üìä Total sections loaded: 1\n",
      "Section 1: 1839 characters\n",
      "Preview: BITTE\n",
      "\n",
      "AI-Powered Customer Service Revolution\n",
      "\n",
      "Series A Funding Pitch\n",
      "\n",
      "2024\n",
      "\n",
      "\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Our...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the necessary libraries\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "import nltk\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Download NLTK resources for text processing\n",
    "print(\"Downloading NLTK resources...\")\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "print(\"‚úÖ NLTK resources downloaded successfully\")\n",
    "\n",
    "# Step 2: Load the PowerPoint presentation using UnstructuredPowerPointLoader\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING POWERPOINT PRESENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the PowerPoint presentation using UnstructuredPowerPointLoader\n",
    "loader = UnstructuredPowerPointLoader('Bitte pitch deck.pptx')\n",
    "docs = loader.load()\n",
    "\n",
    "# Confirm successful loading by printing the number of sections loaded\n",
    "print(f\"‚úÖ Presentation loaded with {len(docs)} sections.\")\n",
    "\n",
    "# Step 3: Display the first section of the loaded PowerPoint to verify data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFYING LOADED CONTENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display the first section of the loaded PowerPoint to verify data\n",
    "print(\"üìÑ First section of the PowerPoint:\")\n",
    "print(docs[0])  # Print the first section of the document\n",
    "\n",
    "# Optional: Display additional information about all sections\n",
    "print(f\"\\nüìä Total sections loaded: {len(docs)}\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Section {i+1}: {len(doc.page_content)} characters\")\n",
    "    if doc.page_content:\n",
    "        print(f\"Preview: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb664a6",
   "metadata": {},
   "source": [
    "# Task 2: Process and Embed PowerPoint Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3397d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SPLITTING DOCUMENT INTO CHUNKS\n",
      "============================================================\n",
      "‚úÖ Number of chunks: 4\n",
      "üìä Chunk size range: 463 - 493 characters\n",
      "üìÑ First chunk preview:\n",
      "'BITTE\n",
      "\n",
      "AI-Powered Customer Service Revolution\n",
      "\n",
      "Series A Funding Pitch\n",
      "\n",
      "2024\n",
      "\n",
      "\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Our Mission\n",
      "\n",
      "To revolutionize the way people interact...'\n",
      "\n",
      "============================================================\n",
      "LOADING EMBEDDING MODEL\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaseen_banu\\AppData\\Local\\Temp\\ipykernel_40048\\781152356.py:25: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\yaseen_banu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hugging Face embedding model loaded successfully.\n",
      "\n",
      "============================================================\n",
      "CREATING FAISS VECTOR DATABASE\n",
      "============================================================\n",
      "‚úÖ Document chunks embedded and stored in FAISS vector database.\n",
      "üìä Number of vectors in FAISS database: 4\n",
      "üìê Vector dimension: 384\n",
      "\n",
      "============================================================\n",
      "POWERPOINT PROCESSING COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPLITTING DOCUMENT INTO CHUNKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Initialize the text splitter with a chunk size of 500 and 50 characters overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# Split the document into chunks\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "# Verify the number of chunks created\n",
    "print(f\"‚úÖ Number of chunks: {len(chunks)}\")\n",
    "\n",
    "# Optional: Display chunk information\n",
    "if chunks:\n",
    "    print(f\"üìä Chunk size range: {min(len(chunk.page_content) for chunk in chunks)} - {max(len(chunk.page_content) for chunk in chunks)} characters\")\n",
    "    print(f\"üìÑ First chunk preview:\")\n",
    "    print(f\"'{chunks[0].page_content[:150]}...'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING EMBEDDING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 2: Load the embedding model from Hugging Face\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Print confirmation of the embedding model loading\n",
    "print(\"‚úÖ Hugging Face embedding model loaded successfully.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING FAISS VECTOR DATABASE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 3: Embed the document chunks as vectors and store them in a FAISS vector database\n",
    "db_faiss = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# Confirm that the data has been stored successfully\n",
    "print(\"‚úÖ Document chunks embedded and stored in FAISS vector database.\")\n",
    "\n",
    "# Optional: Display vector database information\n",
    "print(f\"üìä Number of vectors in FAISS database: {db_faiss.index.ntotal}\")\n",
    "print(f\"üìê Vector dimension: {embedding_model.client[1].get_sentence_embedding_dimension()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POWERPOINT PROCESSING COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c97e3f1",
   "metadata": {},
   "source": [
    "# Task 3: Create Document Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db35ad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING DOCUMENT RETRIEVAL FUNCTION\n",
      "============================================================\n",
      "‚úÖ Document retrieval function created successfully.\n",
      "\n",
      "============================================================\n",
      "TESTING RETRIEVAL FUNCTION\n",
      "============================================================\n",
      "üìÑ Query: 'Who are the founders?'\n",
      "üìä Number of chunks retrieved: 4\n",
      "\n",
      "üîç First retrieved chunk:\n",
      "page_content='Meet Our Founders\n",
      "\n",
      "Sarah Johnson - CEO\n",
      "\n",
      "Former Google Product Manager with 10 years experience\n",
      "\n",
      "Led product development for Google Assistant\n",
      "\n",
      "Michael Chen - CTO\n",
      "\n",
      "Ex-Microsoft Engineer, AI specialist\n",
      "\n",
      "Published 15+ papers on machine learning\n",
      "\n",
      "Emma Rodriguez - CMO\n",
      "\n",
      "Marketing expert from Apple\n",
      "\n",
      "Grew Apple's B2B segment by 300%\n",
      "\n",
      "\n",
      "\n",
      "Market Analysis\n",
      "\n",
      "Target Market\n",
      "\n",
      "Mid to large enterprises with customer service teams\n",
      "\n",
      "E-commerce companies\n",
      "\n",
      "SaaS businesses\n",
      "\n",
      "Healthcare organizations\n",
      "\n",
      "Market Size' metadata={'source': 'Bitte pitch deck.pptx'}\n",
      "\n",
      "============================================================\n",
      "DISPLAYING ALL RETRIEVED CHUNKS\n",
      "============================================================\n",
      "\n",
      "üìÑ Chunk 1:\n",
      "Content: Meet Our Founders\n",
      "\n",
      "Sarah Johnson - CEO\n",
      "\n",
      "Former Google Product Manager with 10 years experience\n",
      "\n",
      "Led product development for Google Assistant\n",
      "\n",
      "Michael Chen - CTO\n",
      "\n",
      "Ex-Microsoft Engineer, AI specialist\n",
      "\n",
      "Published 15+ papers on machine learning\n",
      "\n",
      "Emma Rodriguez - CMO\n",
      "\n",
      "Marketing expert from Apple\n",
      "\n",
      "Grew Apple's B2B segment by 300%\n",
      "\n",
      "\n",
      "\n",
      "Market Analysis\n",
      "\n",
      "Target Market\n",
      "\n",
      "Mid to large enterprises with customer service teams\n",
      "\n",
      "E-commerce companies\n",
      "\n",
      "SaaS businesses\n",
      "\n",
      "Healthcare organizations\n",
      "\n",
      "Market Size\n",
      "Metadata: {'source': 'Bitte pitch deck.pptx'}\n",
      "----------------------------------------\n",
      "\n",
      "üìÑ Chunk 2:\n",
      "Content: BITTE\n",
      "\n",
      "AI-Powered Customer Service Revolution\n",
      "\n",
      "Series A Funding Pitch\n",
      "\n",
      "2024\n",
      "\n",
      "\n",
      "\n",
      "Company Overview\n",
      "\n",
      "Our Mission\n",
      "\n",
      "To revolutionize the way people interact with technology through innovative solutions.\n",
      "\n",
      "Our Product\n",
      "\n",
      "An AI-powered platform that helps businesses automate customer service while maintaining human touch.\n",
      "\n",
      "Unique Selling Point\n",
      "\n",
      "99.9% accuracy in understanding customer intent\n",
      "\n",
      "Seamless integration with existing systems\n",
      "\n",
      "Reduces customer service costs by 60%\n",
      "\n",
      "\n",
      "\n",
      "Meet Our Founders\n",
      "Metadata: {'source': 'Bitte pitch deck.pptx'}\n",
      "----------------------------------------\n",
      "\n",
      "üìÑ Chunk 3:\n",
      "Content: Healthcare organizations\n",
      "\n",
      "Market Size\n",
      "\n",
      "$50B global customer service software market\n",
      "\n",
      "Competition\n",
      "\n",
      "Zendesk: Traditional ticketing system\n",
      "\n",
      "Intercom: Chat-focused solution\n",
      "\n",
      "Salesforce Service Cloud: Enterprise-focused\n",
      "\n",
      "\n",
      "\n",
      "Financial Projections & Funding\n",
      "\n",
      "Revenue Projections\n",
      "\n",
      "Year 1: $2M revenue, 50 enterprise clients\n",
      "\n",
      "Year 2: $8M revenue, 200 clients\n",
      "\n",
      "Year 3: $25M revenue, 500+ clients\n",
      "\n",
      "Funding Ask: $5M Series A\n",
      "\n",
      "Use of Funds\n",
      "\n",
      "40% Product development\n",
      "\n",
      "30% Sales & Marketing\n",
      "\n",
      "20% Team expansion\n",
      "Metadata: {'source': 'Bitte pitch deck.pptx'}\n",
      "----------------------------------------\n",
      "\n",
      "üìÑ Chunk 4:\n",
      "Content: 30% Sales & Marketing\n",
      "\n",
      "20% Team expansion\n",
      "\n",
      "10% Operations\n",
      "\n",
      "Current Team: 25 employees across engineering, sales, and support\n",
      "\n",
      "\n",
      "\n",
      "Technology & Innovation\n",
      "\n",
      "AI Technology Stack\n",
      "\n",
      "Natural Language Processing (NLP)\n",
      "\n",
      "Machine Learning algorithms for intent recognition\n",
      "\n",
      "Deep learning models for conversation flow\n",
      "\n",
      "Key Features\n",
      "\n",
      "Multi-language support (20+ languages)\n",
      "\n",
      "Real-time sentiment analysis\n",
      "\n",
      "Automated escalation to human agents\n",
      "\n",
      "Integration with popular CRM systems\n",
      "Metadata: {'source': 'Bitte pitch deck.pptx'}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING DOCUMENT RETRIEVAL FUNCTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Define a function to retrieve relevant documents based on a query\n",
    "def retrieve_docs(query, k):\n",
    "    # Perform similarity search on the FAISS database using the query\n",
    "    docs_faiss = db_faiss.similarity_search(query, k=k)\n",
    "    \n",
    "    # Return the most relevant document chunks\n",
    "    return docs_faiss\n",
    "\n",
    "print(\"‚úÖ Document retrieval function created successfully.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING RETRIEVAL FUNCTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 2: Test the function with a sample query and retrieve top 5 results\n",
    "context = retrieve_docs('Who are the founders?', 5)\n",
    "\n",
    "# Display the first retrieved chunk to verify correct retrieval\n",
    "print(f\"üìÑ Query: 'Who are the founders?'\")\n",
    "print(f\"üìä Number of chunks retrieved: {len(context)}\")\n",
    "print(f\"\\nüîç First retrieved chunk:\")\n",
    "print(context[0])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISPLAYING ALL RETRIEVED CHUNKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Optional: Display all retrieved chunks with their content\n",
    "for i, doc in enumerate(context, 1):\n",
    "    print(f\"\\nüìÑ Chunk {i}:\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13cdb8",
   "metadata": {},
   "source": [
    "# Task 4: Generate Marketing Campaign Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f2781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SETTING UP MARKETING CAMPAIGN GENERATOR\n",
      "============================================================\n",
      "‚úÖ ChatOpenAI client initialized successfully.\n",
      "‚úÖ Query and system message defined.\n",
      "‚úÖ Retrieved 4 relevant document chunks for context.\n",
      "‚úÖ Messages structured for the assistant.\n",
      "\n",
      "============================================================\n",
      "GENERATING MARKETING CAMPAIGN\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Campaign Title: \"The AI Customer Service Challenge\"**\n",
       "\n",
       "**Target Audience:**\n",
       "- Mid to large enterprises with customer service teams\n",
       "- E-commerce companies\n",
       "- SaaS businesses\n",
       "- Healthcare organizations\n",
       "\n",
       "**Campaign Strategy:**\n",
       "1. **Interactive Online Challenge:**\n",
       "   - Create an engaging online game where participants can experience the AI-powered customer service platform in action. The game will simulate real customer service scenarios where players must choose the best responses to customer inquiries.\n",
       "   - Players will be scored based on their ability to understand customer intent accurately, mirroring the 99.9% accuracy of Bitte's platform.\n",
       "   - Incorporate fun elements like time limits, bonus points for quick responses, and \"power-ups\" that represent the platform's features (e.g., multi-language support, sentiment analysis).\n",
       "\n",
       "2. **Social Media Integration:**\n",
       "   - Encourage participants to share their scores on social media using a dedicated hashtag (e.g., #AIChallengeWithBitte).\n",
       "   - Offer weekly prizes for the highest scores, such as discounts on the service, branded merchandise, or a free consultation session.\n",
       "\n",
       "3. **Webinars and Live Demos:**\n",
       "   - Host live webinars where potential clients can see the platform in action, showcasing its seamless integration and cost-saving benefits.\n",
       "   - Include a Q&A session where attendees can ask questions about the technology and its applications in their industries.\n",
       "\n",
       "4. **Customer Testimonials:**\n",
       "   - Feature video testimonials from existing clients who have successfully implemented Bitte's platform, highlighting the accuracy and cost savings they experienced.\n",
       "\n",
       "**Goals:**\n",
       "- Increase brand awareness and engagement among target audiences.\n",
       "- Generate leads by encouraging participants to sign up for a demo after completing the challenge.\n",
       "- Showcase the unique selling point of 99.9% accuracy in understanding customer intent in a fun and memorable way.\n",
       "- Position Bitte as a thought leader in AI-powered customer service solutions.\n",
       "\n",
       "**Fun Interactive Element:**\n",
       "- At the end of the challenge, participants receive a personalized report detailing their performance, including tips on improving customer service interactions. This report can also include a comparison of their scores with the average score of businesses using Bitte's platform, emphasizing the effectiveness of the AI solution.\n",
       "- Additionally, participants can unlock a \"virtual badge\" for completing the challenge, which they can display on their LinkedIn profiles, further promoting the brand and its innovative approach to customer service. \n",
       "\n",
       "This campaign not only highlights Bitte's unique selling point but also engages potential clients in a fun and interactive way, making the brand memorable and relatable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARKETING CAMPAIGN GENERATED SUCCESSFULLY\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SETTING UP MARKETING CAMPAIGN GENERATOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load env vars\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ChatOpenAI client initialized successfully.\")\n",
    "\n",
    "# Step 2: Define the user query and system prompt\n",
    "# Define the user query\n",
    "query = \"a fun interactive way to showcase the brand's unique selling point\"\n",
    "\n",
    "# Retrieve relevant context based on the user query\n",
    "context = retrieve_docs(query, 10)\n",
    "\n",
    "# Define the system prompt for the assistant\n",
    "system_message = f\"\"\"\n",
    "        You are a marketing expert. Based on the theme and context provided, create a tailored marketing campaign for a brand.\n",
    "        The campaign should include: target audience, campaign strategy, and goals.\n",
    "        Answer the {query} with the {context} provided.\n",
    "    \"\"\"\n",
    "\n",
    "print(\"‚úÖ Query and system message defined.\")\n",
    "print(f\"‚úÖ Retrieved {len(context)} relevant document chunks for context.\")\n",
    "\n",
    "# Step 3: Structure the messages for the assistant\n",
    "messages = [(\"system\", system_message), (\"human\", query)]\n",
    "\n",
    "print(\"‚úÖ Messages structured for the assistant.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING MARKETING CAMPAIGN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 4: Generate and display the marketing campaign\n",
    "# Generate and display the response from the assistant\n",
    "response = llm.invoke(messages)  # Call the API with the messages\n",
    "\n",
    "# Display the response in markdown format\n",
    "display(Markdown(response.content))  # Display the response in markdown format\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MARKETING CAMPAIGN GENERATED SUCCESSFULLY\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d8215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae085a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
